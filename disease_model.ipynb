{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3e6f1577-b2ef-4f80-b934-fad66d3fee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ruamel.yaml in /Users/heathercornell/opt/anaconda3/lib/python3.9/site-packages (0.17.21)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /Users/heathercornell/opt/anaconda3/lib/python3.9/site-packages (from ruamel.yaml) (0.2.6)\n"
     ]
    }
   ],
   "source": [
    "#!pip install ruamel.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4663a9df-fa3f-4aed-b6f1-896b12579476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "import seaborn as sn\n",
    "from ruamel.yaml import YAML\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0ffaaa2f-0923-4ef7-bb2a-67ad9e1b4115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params():\n",
    "    \"Updates FULL_PARAMS with the values in params.yaml and returns all as a dictionary\"\n",
    "    yaml = YAML(typ=\"safe\")\n",
    "    with open(\"params.yaml\") as f:\n",
    "        params = yaml.load(f)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2d6a2b6f-fb02-4e70-bbd1-a24e9682d870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import text\n",
    "x_train = pd.read_csv ('dengue_features_train.csv', na_values=' NAN')\n",
    "y_train=pd.read_csv('dengue_labels_train.csv', na_values=' NAN')\n",
    "test =pd.read_csv ('dengue_features_test.csv', na_values=' NAN')\n",
    "test=test.drop(columns=['city', 'year', 'week_start_date'])\n",
    "y_train=y_train.drop(columns=['city', 'year'])\n",
    "x_train=x_train.drop(columns=['city', 'year', 'week_start_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f0a8aad1-06ab-4680-8045-49dc4dd24dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekofyear                               0.216452\n",
      "ndvi_ne                                 -0.241376\n",
      "ndvi_nw                                 -0.202235\n",
      "ndvi_se                                 -0.168612\n",
      "ndvi_sw                                 -0.196461\n",
      "precipitation_amt_mm                    -0.038740\n",
      "reanalysis_air_temp_k                    0.264952\n",
      "reanalysis_avg_temp_k                    0.151637\n",
      "reanalysis_dew_point_temp_k              0.142531\n",
      "reanalysis_max_air_temp_k               -0.191345\n",
      "reanalysis_min_air_temp_k                0.325252\n",
      "reanalysis_precip_amt_kg_per_m2         -0.010031\n",
      "reanalysis_relative_humidity_percent    -0.132452\n",
      "reanalysis_sat_precip_amt_mm            -0.038740\n",
      "reanalysis_specific_humidity_g_per_kg    0.129861\n",
      "reanalysis_tdtr_k                       -0.278483\n",
      "station_avg_temp_c                       0.116109\n",
      "station_diur_temp_rng_c                 -0.237844\n",
      "station_max_temp_c                      -0.039219\n",
      "station_min_temp_c                       0.267109\n",
      "station_precip_mm                       -0.074374\n",
      "total_cases                              1.000000\n",
      "Name: total_cases, dtype: float64\n",
      "['weekofyear', 'ndvi_ne', 'ndvi_nw', 'reanalysis_air_temp_k', 'reanalysis_min_air_temp_k', 'reanalysis_tdtr_k', 'station_diur_temp_rng_c', 'station_min_temp_c', 'total_cases']\n"
     ]
    }
   ],
   "source": [
    "#data analysis\n",
    "minCorr = .2\n",
    "x_train['total_cases']=y_train['total_cases']\n",
    "corrMatrix = x_train.corr()\n",
    "lastCol=corrMatrix.iloc[:,-1]\n",
    "print(lastCol)\n",
    "features=list(lastCol.loc[abs(lastCol) > minCorr].index)\n",
    "print(features)\n",
    "x_train=x_train[features]\n",
    "corrMatrix = x_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "57f0297e-5c33-4810-a6d9-1bf1fa7cdcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "#remove NaN\n",
    "x_train['total_cases']=y_train['total_cases']\n",
    "x_train=x_train.dropna()\n",
    "test=test.dropna()\n",
    "y_train=x_train['total_cases']\n",
    "x_train=x_train.drop(columns=['total_cases'])\n",
    "#separate again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aa6f0d52-d8bb-4bf0-855d-ef59f982827b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 24.346916\n",
      "Training Score:  0.877670896983071\n",
      "Mean cross-val score: 0.12\n",
      "K-fold CV average score: 0.09\n",
      "MSE: 593.53\n",
      "RMSE: 24.362420\n",
      "Accuracy: 2.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "#X, y = x_train.iloc[:,:-1],y_train.iloc[:,-1]\n",
    "X_train, X_test, Y_train, y_test = train_test_split(x_train, y_train, test_size=0.33)\n",
    "\n",
    "#bagging model\n",
    "\n",
    "dt_model = DecisionTreeRegressor()\n",
    "X, y = make_regression(n_samples=1000, n_informative=15, noise=0.1, random_state=1)\n",
    "bagModel = BaggingRegressor(dt_model, n_estimators=22, max_features=1.0)\n",
    "bagModel.fit(X_train, Y_train)\n",
    "preds = bagModel.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "#scoring the model\n",
    "score = bagModel.score(X_train, Y_train)\n",
    "print(\"Training Score: \", score)\n",
    "\n",
    "#cross-val score\n",
    "scores = cross_val_score(bagModel, X_train, Y_train, cv=10)\n",
    "print(\"Mean cross-val score: %.2f\" % scores.mean())\n",
    "\n",
    "#K-Fold cross-val\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "kf_cv_scores = cross_val_score(bagModel, X_train, Y_train, cv=kfold )\n",
    "print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())\n",
    "\n",
    "#MSE and RMSE\n",
    "preds = bagModel.predict(X_test)\n",
    "preds = [round(value) for value in preds]\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "print(\"MSE: %.2f\" % mse)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "#accuracy score\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bda9ad8a-18a9-4181-89ac-d67ba7d3aa22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator__ccp_alpha': 0.0,\n",
       " 'base_estimator__criterion': 'squared_error',\n",
       " 'base_estimator__max_depth': None,\n",
       " 'base_estimator__max_features': None,\n",
       " 'base_estimator__max_leaf_nodes': None,\n",
       " 'base_estimator__min_impurity_decrease': 0.0,\n",
       " 'base_estimator__min_samples_leaf': 1,\n",
       " 'base_estimator__min_samples_split': 2,\n",
       " 'base_estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'base_estimator__random_state': None,\n",
       " 'base_estimator__splitter': 'best',\n",
       " 'base_estimator': DecisionTreeRegressor(),\n",
       " 'bootstrap': True,\n",
       " 'bootstrap_features': False,\n",
       " 'max_features': 1.0,\n",
       " 'max_samples': 1.0,\n",
       " 'n_estimators': 22,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagModel.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "abdc0b3e-4295-415d-9be4-f9b056d2e613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking different metrics for bagging model with default hyper parameters:\n",
      "\n",
      "Training accuracy:  0.9950617283950617\n",
      "Testing accuracy:  0.99\n",
      "Fitting 3 folds for each of 125 candidates, totalling 375 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heathercornell/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "/Users/heathercornell/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "150 fits failed out of a total of 375.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/heathercornell/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/heathercornell/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py\", line 269, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"/Users/heathercornell/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py\", line 342, in _fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/heathercornell/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.09170905 0.08594371 0.08841895 0.08346436 0.08676879 0.0710697\n",
      " 0.08098297 0.08098502 0.09089215 0.08511453 0.07272805 0.07933486\n",
      " 0.08098502 0.08511248 0.07933486 0.08016403 0.07520944 0.08263314\n",
      " 0.08098912 0.08760001 0.08348074 0.08677493 0.08677288 0.08677698\n",
      " 0.0834787  0.07851387 0.08098707 0.08016403 0.09007321 0.08841486\n",
      " 0.08264338 0.08181625 0.0867606  0.08097683 0.08346436 0.08428945\n",
      " 0.08760206 0.09419248 0.08510634 0.088421   0.08182648 0.08511248\n",
      " 0.08676879 0.08594575 0.08263723 0.08099731 0.07768264 0.08760001\n",
      " 0.08511453 0.08263723 0.07356747 0.09254232 0.08676469 0.08923585\n",
      " 0.08346232 0.08347255 0.08511658 0.08347051 0.08510634 0.09006093\n",
      " 0.08429149 0.08264747 0.08924813 0.09255256 0.08924404 0.08841895\n",
      " 0.08924813 0.088421   0.08676879 0.08760206 0.07438027 0.08346846\n",
      " 0.08511862 0.0818101  0.08347051        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyper parameters are:\n",
      " {'max_features': 2, 'max_samples': 25, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "#Fitting Bagging Classifier model with default hyper parameters\n",
    "bagg = BaggingClassifier()\n",
    "bagg.fit(x_train,y_train)\n",
    "pred_bagg = bagg.predict(X_test)\n",
    "\n",
    "#Checking different metrics for bagging model with default hyper parameters\n",
    "print('Checking different metrics for bagging model with default hyper parameters:\\n')\n",
    "print(\"Training accuracy: \",bagg.score(X_train,Y_train))\n",
    "acc_score = accuracy_score(y_test, pred_bagg)\n",
    "print('Testing accuracy: ',acc_score)\n",
    "\n",
    "#Setting values for the parameters\n",
    "n_estimators = [100, 300, 500, 800, 1200]\n",
    "#max_depth = [5, 10, 15, 25, 30]\n",
    "max_samples = [5, 10, 25, 50, 100]\n",
    "max_features = [1, 2, 5, 10, 13]\n",
    "\n",
    "#Creating a dictionary for the hyper parameters\n",
    "hyperbag = dict(n_estimators = n_estimators, max_samples = max_samples, \n",
    "              max_features = max_features)\n",
    "\n",
    "#Applying GridSearchCV to get the best value for hyperparameters\n",
    "gridbag = GridSearchCV(bagg, hyperbag, cv = 3, verbose = 1, n_jobs = -1)\n",
    "bestbag = gridbag.fit(x_train, y_train)\n",
    "\n",
    "#Printing the best hyperparameters\n",
    "print('The best hyper parameters are:\\n',gridbag.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "be58052f-6eb0-48f6-bd40-88ee68248614",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max_features must be in (0, n_features]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/my/2m5bj6js22nf61rxhzsjw3500000gn/T/ipykernel_27113/4226480811.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Fitting the bagging model with the best hyper parameters obtained through GridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbagg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaggingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbagg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpred_bagg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbagg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         )\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_features must be in (0, n_features]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max_features must be in (0, n_features]"
     ]
    }
   ],
   "source": [
    "#Fitting the bagging model with the best hyper parameters obtained through GridSearchCV\n",
    "bagg1 = BaggingClassifier(max_features=10, max_samples=25,n_estimators= 100)\n",
    "bagg1.fit(X_train,Y_train)\n",
    "pred_bagg1 = bagg1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517532a9-bd12-4e17-afae-ccd33f185d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization to see if it looks like it matches\n",
    "x_ax = range(len(y_test))\n",
    "plt.plot(x_ax, y_test, label=\"original\")\n",
    "plt.plot(x_ax, preds, label=\"predicted\")\n",
    "plt.title(\"Predicted vs Original data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bff0ce6-4710-4260-999a-fe04554cb9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a graph called stats.png\n",
    "plt.tight_layout()\n",
    "fig1 = plt.gcf()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "fig1.savefig('stats.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68555a05-f1b1-4acd-87dc-8cbab52f40e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit predictions fo test\n",
    "def submit(model, test):\n",
    "  pred=model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b0702-806f-4988-91b2-8b2d9658ded8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
